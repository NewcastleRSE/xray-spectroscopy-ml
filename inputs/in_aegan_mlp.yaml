xyz_path:  data/fe/xyz_train
xanes_path:  data/fe/xanes_train

descriptors:
  - type: wacsf
    params:
      r_min: 1.0
      r_max: 6.0
      n_g2: 16
      n_g4: 32

model:
  type: aegan_mlp
  params:
      hidden_size: 256
      dropout: 0.0
      n_hl_gen: 2
      n_hl_shared: 2
      n_hl_dis: 2
      activation: prelu
      lr_gen: 0.01
      lr_dis: 0.0001
      optim_fn_gen: Adam
      optim_fn_dis: Adam
      loss_gen:
        loss_fn: mse
        loss_args: 10
        loss_reg_type: null # null, L1, L2
        loss_reg_param: 0.001
      loss_dis:
        loss_fn: bce
        loss_args: null
        loss_reg_type: null # null, L1, L2
        loss_reg_param: 0.001

hyperparams:
  batch_size: 64
  epochs: 100
  kernel_init: xavier_uniform
  bias_init: zeros
  model_eval: True
  seed: 2021
  weight_seed: 2023

kfold: False
kfold_params:
  n_splits: 5
  n_repeats: 1
  seed: 2022

lr_scheduler: True
scheduler_params:
    type: step
    step_size: 50
    gamma: 0.1

data_augment: False
augment_params:
  type: random_noise
  # augment_type: random_combination
  augment_mult: 5
  # for random noise
  augment_params:
    normal_mean: 0
    normal_sd: 0.1
  # for random combination
  # augment_params : {}

bootstrap: False
bootstrap_params:
  n_boot: 3
  n_size: 1.0
  weight_seed: [97, 39, 22]

ensemble: False
ensemble_params:
  n_ens: 3
  weight_seed: [97, 39, 22]

optuna: False
optuna_params:
  n_trials: 3
  tune_batch_size: True
  tune_aegan_mlp: True

freeze: False
freeze_params:
  model_path: ./models/model_aegan_mlp_001
  n_encoder1: 1
  n__encoder2: 1
  n_decoder1: 1
  n_decoder2: 1
  n_shared_encoder: 1
  n_shared_decoder: 1
  n_discrim1: 1
  n_discrim2: 1

fourier_transform: False
fourier_params:
  concat: True

standardscaler: False